# Automatic emotion recognition in speech

The goal of this project was to reproduce the results in the papers [4] and [5].
Using corpora AIBO [1] and EMO-DB [2] as training and test datasets.
Using OpenSmile[3] tool to extract acoustic features.

## Credits

[1] http://www5.cs.fau.de/de/mitarbeiter/steidl-stefan/fau-aibo-emotion-corpus/

[2] http://emodb.bilderbar.info/docu/

[3] http://audeering.com/technology/opensmile/

[4] Björn Schuller and Stefan Steidl and Anton Batliner, “The INTERSPEECH 2009 Emotion Challenge,”
In proc. of Interspeech, Brighton, U.K., 2009.

[5] George Trigeorgis et al., “Adieu Features? End-to-end speech emotion recognition using a Deep Convo-
lutional Recurrent Network,” In proc. of ICASSP, Shanghai, China, 2016.
